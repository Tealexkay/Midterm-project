{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tealexkay/Midterm-project/blob/main/Day2_basics_managing_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SK_NiMUsABaO"
      },
      "source": [
        "# Day 2: Managing Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMU6qoe7ABaQ"
      },
      "source": [
        "## 1. What is data? What is a dataset?\n",
        "Data can be thought of as **information** stored in some format that can be used for **analysis** or other computational tasks. A **dataset** is simply a collection of such data.\n",
        "\n",
        "Examples:\n",
        "- A table of users with columns such as name, age, and country.\n",
        "- A CSV file containing all the transactions for an online store.\n",
        "- A JSON file containing responses from an API.\n",
        "\n",
        "### Why do we care?\n",
        "- We use data to find **patterns**, **insights**, and **answer questions**.\n",
        "- Data is the foundation of **data analysis**,**machine learning**, **data science**, and many business **decision-making** processes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SMXBeIvABaQ"
      },
      "source": [
        "## 2. Formats for data\n",
        "Data can be stored in many different file formats, each with its own advantages and disadvantages:\n",
        "\n",
        "- **CSV (Comma-Separated Values):** Simple, plain-text files. Easy to read and widely used.\n",
        "- **JSON (JavaScript Object Notation):** Common for web APIs, easy to parse, can store nested data.\n",
        "- **XLSX (Excel spreadsheets):** Common in business settings, can contain multiple sheets.\n",
        "- **Plain text (TXT):** Flexible but usually less structured.\n",
        "- Others: **Parquet**, **HDF5**, **SQL databases**, etc.\n",
        "\n",
        "Knowing how data is stored and how to read it is crucial for data analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbxAFPsGABaQ"
      },
      "source": [
        "## 3. Where to find data online?\n",
        "If you don’t have your own data, you can:\n",
        "\n",
        "- Use **open data portals** (e.g., [data.gov](https://www.data.gov/), [Kaggle Datasets](https://www.kaggle.com/datasets),etc).\n",
        "- Download data from **public repositories** on GitHub.\n",
        "- Use **APIs** to query data directly (e.g., Twitter API, OpenWeatherMap, etc.).\n",
        "- Create your own data by **scraping websites**, or by collecting logs from an application.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. What are Libraries (Packages) ?\n",
        "\n",
        "In **Python**, a **library** is a collection of modules and functions that provide reusable code to perform common tasks. Libraries help developers save time by offering ready-made solutions for various purposes, such as mathematical operations, data analysis, web development, and more.\n",
        "\n",
        "Using libraries allows you to focus on solving your specific problem instead of writing everything from scratch. For instance, instead of manually writing code to handle large datasets, you can use a library like **Pandas** to simplify the process.\n",
        "\n",
        "\n",
        "NOTE: The terms libraries and packages are sometimes used interchangeably, even though they have distinct meanings. However, in casual usage, people often refer to them as the same thing.\n",
        "\n",
        "### Examples of Popular Python Libraries\n",
        "\n",
        "- **NumPy**: For numerical computations\n",
        "- **Pandas**: For data analysis and manipulation\n",
        "- **Matplotlib**: For data visualization\n",
        "- **Seaborn**: For statistical data visualization\n",
        "\n",
        "## How to Load a Library\n",
        "\n",
        "To load a library in Python, you use the `import` statement. Here are different ways to import and use libraries:\n",
        "\n",
        "### Importing the Entire Library\n",
        "\n",
        "The simplest way to use a library is to import it entirely:"
      ],
      "metadata": {
        "id": "_RKOFqw1FEb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "import numpy"
      ],
      "metadata": {
        "id": "Hy6gK-0PFEAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing with an Alias\n",
        "\n",
        "You can import a library with an **alias** to make your code more concise and readable, especially if the library name is long. This is useful when a library is used frequently throughout your code.\n",
        "\n",
        "To give an alias to a library, you use the `as` keyword:"
      ],
      "metadata": {
        "id": "t0Ag125wF0sO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "W00Kr_8_F3Ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE: You can install packages that are not pre-installed in Google Colab by running **!pip install package_name** in a code cell if necessary. Additionally, if you choose to run your notebooks locally using an IDE such as VS Code, remember that you may need to install the required packages beforehand."
      ],
      "metadata": {
        "id": "XFl3OwQnF_w1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZWmPXztABaS"
      },
      "source": [
        "\n",
        "\n",
        "## 5. Using pandas to load data (Intro to DataFrames)\n",
        "A **DataFrame** is a 2-dimensional labeled data structure with columns (like a spreadsheet).\n",
        "\n",
        "### Example of loading a dataset\n",
        "Let's create a small dictionary **on the fly** and load it using **pandas**:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qGL7YRKABaS"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
        "    'Age': [24, 30, 22, 25, 28],\n",
        "    'Score': [88, 92, 85, 91, 95]\n",
        "}\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqDxlkv1ABaQ"
      },
      "source": [
        "## 6. How to use data in Google Colab?\n",
        "There are multiple ways to bring your data into Colab:\n",
        "\n",
        "1. **Upload directly** to Colab.\n",
        "2. **Connect to Google Drive**:\n",
        "   - Mount your Drive and read the file as if it’s in your local filesystem.\n",
        "3. **Use a raw link from GitHub**:\n",
        "   - If the data is hosted in a public repo, you can obtain a **raw file link** to read directly.\n",
        "4. **Using APIs** (not covered in this class), you can retrieve data using `requests` or other libraries.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dWiN51dABaR"
      },
      "source": [
        "### Example: Connect to Google Drive\n",
        "Below is how you could connect your notebook to your Google Drive in Colab:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wP-AfW6wABaR"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Uncomment and run the following in Google Colab:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "# After mounting, you can access files in 'My Drive' under '/content/drive/My Drive'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example importing data from my google drive (you need to update the link for the data in your drive)\n",
        "import pandas as pd\n",
        "weather_drive= pd.read_csv(\"/content/drive/MyDrive/Lehman College Spring 2025/MAT 301/datasets/KNYC.csv\")\n",
        "weather_drive.head()"
      ],
      "metadata": {
        "id": "7C4kw5JbD0DY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE8m5TWwABaR"
      },
      "source": [
        "### Example: Using a raw link from GitHub\n",
        "You can directly pass a **raw GitHub URL** to pandas (or `requests` library) to read the data:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBcW-wEsABaR"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Example CSV file hosted on GitHub (raw link)\n",
        "url = \"https://raw.githubusercontent.com/liger1apwm/MAT-301_Applied_Stats_Data_Analysis/refs/heads/main/data/KNYC.csv\"\n",
        "weather_github = pd.read_csv(url)\n",
        "weather_github.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this way is preferred if"
      ],
      "metadata": {
        "id": "qZNJAIjVEhUq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example: Reading a .xlsx file"
      ],
      "metadata": {
        "id": "Za2QXSlut-m5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Replace with your actual file path\n",
        "file_path = \"/content/drive/MyDrive/Lehman College Spring 2025/MAT 301/datasets/Canada.xlsx\"\n",
        "\n",
        "# Read the Excel file, all sheet\n",
        "excel_df = pd.read_excel(file_path, sheet_name=None)\n",
        "\n",
        "\n",
        "excel_df"
      ],
      "metadata": {
        "collapsed": true,
        "id": "UWpFChigvrPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "to read an specific sheet and skiprows we can do the following:"
      ],
      "metadata": {
        "id": "XLt6VIQSxDiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "excel_df_sheet = pd.read_excel(file_path, sheet_name=\"Canada by Citizenship\", skiprows=1)\n",
        "\n",
        "\n",
        "excel_df_sheet"
      ],
      "metadata": {
        "id": "ZQw6KBLcwdJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4lC9neUABaS"
      },
      "source": [
        "## 7. Exploring Data\n",
        "### 7.1 Checking the beginning, end, or random rows\n",
        "- `df.head()` shows the **first 5** rows.\n",
        "- `df.tail()` shows the **last 5** rows.\n",
        "- `df.sample()` shows **random** rows.\n",
        "\n",
        "In any of the previous functions, we can pass an integer as input, which will adjust the number of rows displayed depending on the value of the integer.\n",
        "- If the integer is positive, it will return the first n rows.\n",
        "- If the integer is negative, it will return all rows except the last n rows.\n",
        "\n",
        "### 7.2 Checking column types\n",
        "Use `df.dtypes` to see the data types of all columns.\n",
        "\n",
        "Sometimes, numeric columns are stored as **strings**. We can convert them by using `pd.to_numeric()` or other appropriate functions.\n",
        "\n",
        "### 7.3 Date columns\n",
        "It's helpful to store dates as **datetime** objects. We can convert them with `pd.to_datetime()`.\n",
        "\n",
        "If date columns remain as strings, pandas can’t easily perform date/time operations like extracting the **month**, **year**, or calculating **durations** between dates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9D1QjLeABaS"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Exploring the DataFrame\n",
        "\n",
        "print(\"HEAD:\")\n",
        "display(weather_github.head(2))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTAIL:\")\n",
        "display(weather_github.tail(2))"
      ],
      "metadata": {
        "id": "YbmY3CCeKojt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nSAMPLE:\")\n",
        "display(weather_github.sample(2))\n"
      ],
      "metadata": {
        "id": "09KdHXy_Kp-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nDATA TYPES:\")\n",
        "print(weather_github.dtypes)\n"
      ],
      "metadata": {
        "id": "iyvWFfrIKslG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting Date column to datetime\n",
        "\n",
        "weather_github['date'] = pd.to_datetime(weather_github['date'])\n",
        "print(\"\\nDATA TYPES AFTER CONVERSION:\")\n",
        "print(weather_github.dtypes)\n",
        "\n"
      ],
      "metadata": {
        "id": "R05ve4WIKwkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: extracting year from Date\n",
        "\n",
        "weather_github['Year'] = weather_github['date'].dt.year\n",
        "print(\"\\nHEAD AFTER ADDING YEAR COLUMN:\")\n",
        "display(weather_github.head(2))"
      ],
      "metadata": {
        "id": "5YlpZbA-LEV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwuoLAgxABaS"
      },
      "source": [
        "## 8. Detecting and Dealing with Missing Values or Duplicates\n",
        "### 8.1 Missing Values\n",
        "Missing values appear as **NaN** in pandas. We can detect them using:\n",
        "- `df.isnull()` or `df.isna()` (they are equivalent in pandas).\n",
        "- Summarize with `df.isnull().sum()` to see how many missing values in each column.\n",
        "\n",
        "We can **fill** missing values or **drop** rows containing missing values:\n",
        "- `df.fillna(value)` to fill.\n",
        "- `df.dropna()` to drop.\n",
        "\n",
        "### 8.2 Duplicates\n",
        "Duplicate rows can be detected with `df.duplicated()` and removed with `df.drop_duplicates()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf_vaFmBABaS"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Example of missing values\n",
        "import numpy as np\n",
        "\n",
        "# Introduce a missing value\n",
        "weather_github.loc[1, 'Name'] = np.nan\n",
        "display(weather_github.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect missing values\n",
        "print(\"Missing values per column:\")\n",
        "print(weather_github.isnull().sum())\n",
        "\n"
      ],
      "metadata": {
        "id": "hYZIo963NKSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing name with 'Unknown'\n",
        "weather_github['Name'].fillna('Unknown', inplace=True) #use .dropna() to eliminate the rows with na\n",
        "display(weather_github.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "7c7Hdu_DNPkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of duplicate row\n",
        "weather_github_duplicate = pd.concat([weather_github.iloc[[0]],weather_github], ignore_index=True)\n",
        "\n",
        "print(\"\\nCheck duplicate row:\")\n",
        "\n",
        "weather_github_duplicate.head()\n"
      ],
      "metadata": {
        "id": "7yFqu7YANQpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find duplicate rows\n",
        "duplicates = weather_github_duplicate.duplicated()\n",
        "\n",
        "# Display duplicate rows\n",
        "weather_github_duplicate[duplicates]"
      ],
      "metadata": {
        "id": "cuvkgroRPu6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicates\n",
        "weather_github_duplicate.drop_duplicates(inplace=True)\n",
        "print(\"After dropping duplicates:\")\n",
        "display(weather_github_duplicate.head())"
      ],
      "metadata": {
        "id": "NfEEdaCfNR2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EU6E5fA0ABaS"
      },
      "source": [
        "## 9. Selecting Desired Columns\n",
        "If you only need certain columns from the DataFrame, you can **select** them by name.\n",
        "\n",
        "```python\n",
        "df[['date', 'temp']]\n",
        "```\n",
        "\n",
        "Example:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting columns\n",
        "weather_subset = weather_github[['date', 'actual_mean_temp']]\n",
        "print(\"\\nSubset of DataFrame (date, actual_mean_temp):\")\n",
        "display(weather_subset.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "nHUwzy8dSLMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Creating a New Column Based on Another Column\n",
        "You can create a **new column** by applying an operation or function to an existing column. For example, if you have an Age column, you might convert age to the number of months:\n",
        "\n",
        "Example:\n",
        "\n",
        "```python\n",
        "df['Age_in_Months'] = df['Age'] * 12\n",
        "```\n",
        "\n",
        "Or apply a more complex function.\n",
        "\n",
        "Now, lets see an example using the previous weather data:"
      ],
      "metadata": {
        "id": "j-sHJMSASNQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a new column\n",
        "weather_subset['temp_celcius'] = (weather_subset['actual_mean_temp'] - 32) * 5 / 9.0\n",
        "print(\"DataFrame with new column 'temp_celcius':\")\n",
        "display(weather_subset.head())"
      ],
      "metadata": {
        "id": "oQBorwimQnDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE: To suppress the warning, you can use the following code beforehand. However, always ensure you understand what you are suppressing, as some warnings can help prevent future errors."
      ],
      "metadata": {
        "id": "kxxMLaH5RPa5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "# Suppress all warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Creating a new column\n",
        "weather_subset['temp_celcius'] = (weather_subset['actual_mean_temp'] - 32) * 5 / 9.0\n",
        "print(\"DataFrame with new column 'temp_celcius':\")\n",
        "display(weather_subset.head())"
      ],
      "metadata": {
        "id": "DBNLO_9_RiR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2M4cftMABaS"
      },
      "source": [
        "# Summary\n",
        "In **Day 2**, we covered:\n",
        "1. Understanding data and datasets\n",
        "2. Common file formats\n",
        "3. Ways to source data (online, created, or via APIs)\n",
        "4. Using data in Google Colab (Drive, GitHub)\n",
        "5. Important Python libraries for data management (pandas, numpy)\n",
        "6. Loading data into pandas DataFrames\n",
        "7. Exploring data (head, tail, sample, dtypes)\n",
        "8. Handling date/time fields\n",
        "9. Dealing with missing and duplicate data\n",
        "10. Selecting and creating new columns\n",
        "\n",
        "In the next sessions, we'll dig deeper into data cleaning, transformation, and visualization!"
      ]
    }
  ]
}