{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tealexkay/Midterm-project/blob/main/Day3_wrangling_data_measure_central_tendency.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR50UCYwJasr"
      },
      "source": [
        "# Day 3: Wrangling Data and Exploring Measures of Central Tendency\n",
        "\n",
        "In today‚Äôs session, we will build on what we learned about **managing data** (from Day 2) and move on to **data wrangling**. We‚Äôll cover slicing, sorting, grouping, and then dive into **measures of central tendency**‚Äîincluding the **mean**, **median**, **mode**, and **trimmed mean**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOvfrQq1Jast"
      },
      "source": [
        "## Quick Review from Previous Class\n",
        "* a. **Recap of Key Concepts from Day 2**\n",
        "   - How to import data using `pandas`.\n",
        "   - The basics of exploring a DataFrame (`df.head()`, `df.tail()`, `df.sample()`, `df.dtypes`).\n",
        "   - Managing missing values and duplicates.\n",
        "* b. **Selecting a subset of columns and Creating new columns**\n",
        "   - Much of your analysis depends on selecting **relevant subsets** of your data.\n",
        "   - Create new columns based on calculations or conditions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Loading Data"
      ],
      "metadata": {
        "id": "Lq-vtdveYTZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets import the data from the following url using pandas, save it into a variable called `nfl_suspension_df`:\n",
        "\n",
        "```python\n",
        "https://raw.githubusercontent.com/liger1apwm/MAT-301_Applied_Stats_Data_Analysis/refs/heads/main/data/nfl-suspensions-data.csv\n",
        "```\n"
      ],
      "metadata": {
        "id": "RQErRQTTLmmT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üèà NFL Suspensions Dataset  \n",
        "\n",
        "This dataset contains information about **NFL player suspensions**, particularly focusing on the **league‚Äôs disciplinary actions**. It is based on the story *The NFL‚Äôs Uneven History Of Punishing Domestic Violence*. The dataset includes details on players, suspension reasons, and the number of games missed.\n",
        "\n",
        "#### üìä Dataset Overview  \n",
        "The dataset consists of multiple suspensions, categorized by **personal conduct**, **substance abuse**, **performance-enhancing drugs**, and **in-game violence**.\n",
        "\n",
        "#### üîç Column Descriptions  \n",
        "\n",
        "| **Column**  | **Definition** |\n",
        "|------------|--------------|\n",
        "| `name`     | Player's name (formatted as first initial.last name). |\n",
        "| `team`     | Team the player was part of at the time of suspension. |\n",
        "| `games`    | Number of games suspended (one regular season = 16 games). |\n",
        "| `category` | The reason for suspension (e.g., personal conduct, substance abuse, performance-enhancing drugs, in-game violence). |\n",
        "| `desc.`    | A brief description of the suspension incident. |\n",
        "| `year`     | The year the suspension occurred. |\n",
        "| `source`   | The news source reporting the suspension. |"
      ],
      "metadata": {
        "id": "QXxwabffY0fo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**lets load the data and take a look a the first 10 rows.**"
      ],
      "metadata": {
        "id": "K4lr6P9bY4fY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7WmJjEcqLnAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details><summary>Answer:</summary>\n",
        "<code>\n",
        "import pandas as pd</br>\n",
        "nfl_suspension_df = pd.read_csv('https://raw.githubusercontent.com/liger1apwm/MAT-301_Applied_Stats_Data_Analysis/refs/heads/main/data/nfl-suspensions-data.csv') </br>\n",
        "nfl_suspension_df.head(10) </br>\n",
        "</code>\n",
        "</details>"
      ],
      "metadata": {
        "id": "sJkPvB_TLy_3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets just select the columns `name, team, games, category, year` and then find out their datatype:"
      ],
      "metadata": {
        "id": "gKMup3e0Sa-f"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j6MNJtIPSztw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details><summary>Answer:</summary>\n",
        "<code>\n",
        "nfl_suspension_df = nfl_suspension_df[['name','team','games','category','year']] </br>\n",
        "nfl_suspension_df.dtypes</br>\n",
        "</code>\n",
        "</details>"
      ],
      "metadata": {
        "id": "s1GX0bimSzNo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In **pandas**, the object data type is a catch-all data type for string or mixed data (e.g., text, special characters, or even mixed types in a column). When pandas can‚Äôt infer a more specific type (like int, float, or datetime), it assigns the object type.\n",
        "\n",
        "**What do you think the datatypes should be?**"
      ],
      "metadata": {
        "id": "u67M55wEUOMW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### pandas .astype() function\n",
        "\n",
        "To change the datatype of a column we can use the .astype function, for example:\n",
        "\n",
        "For one column at the time:\n",
        "\n",
        "```python\n",
        "# Convert 'Age' to int\n",
        "df['Age'] = df['Age'].astype(int)\n",
        "```\n",
        "Multiple columns at once:\n",
        "\n",
        "```python\n",
        "df = df.astype({\n",
        "    'Age': 'int',\n",
        "    'Join_Date': 'datetime64[ns]',\n",
        "    'Salary': 'float'\n",
        "})\n",
        "```\n",
        "\n",
        "Using this example lets change the datatypes for each column in our dataframe except for games (we will see later why we are not doing it now):"
      ],
      "metadata": {
        "id": "iJ3OXOA9U4QY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nfl_suspension_df = nfl_suspension_df.astype({\n",
        "    'name': 'string',\n",
        "    'team': 'string',\n",
        "    'category': 'string',\n",
        "    'year': 'int16'\n",
        "})\n",
        "\n",
        "nfl_suspension_df.dtypes"
      ],
      "metadata": {
        "id": "GcS3xePLVteL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the data types have been adjusted to fit our needs, we can proceed with the next steps in working with our DataFrame."
      ],
      "metadata": {
        "id": "WF_9hMqWVP_D"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sPtRGtMJast"
      },
      "source": [
        "## 2. Wrangling Data (modifying the dataframe)\n",
        "### 2.1 More on Slicing DataFrames\n",
        "We can slice or filter rows and columns in `pandas` in multiple ways:\n",
        "- **`.loc`**: label-based indexing (i.e., based on row labels or column names).\n",
        "- **`.iloc`**: integer-based indexing (i.e., based on row/column integer positions).\n",
        "\n",
        "Using .loc:\n",
        "\n",
        "```python\n",
        "# Select rows by index labels and specific columns\n",
        "# Get rows with index labels 1 to 3 and columns 'Player' and 'Score'\n",
        "print(df.loc[1:3, ['Player', 'Score']])\n",
        "\n",
        "# Select a single row by its index label\n",
        "print(df.loc[2])\n",
        "```\n",
        "Using .iloc:\n",
        "\n",
        "```python\n",
        "# Select rows by integer positions and specific columns\n",
        "# Get the first 3 rows and the first 2 columns\n",
        "print(df.iloc[0:3, 0:2])\n",
        "\n",
        "# Select a single row by its integer position\n",
        "print(df.iloc[4])\n",
        "```\n",
        "\n",
        "We can also slice using **conditional expressions** (e.g., `df[df['Age'] > 30]`) and combine multiple conditions with **AND** (`&`) or **OR** (`|`)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets now take care of the games column datatype, **What is an issue that we may encounter if we try to change the datatype of the games column?**\n",
        "\n",
        "Lets try to change the type to int and see what happends:\n",
        "\n"
      ],
      "metadata": {
        "id": "T0Tu4B7VfHsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nfl_suspension_df['games'] = nfl_suspension_df['games'].astype(int)"
      ],
      "metadata": {
        "id": "p0Gipri0iA3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that some columns contain string values that cannot be converted to numbers. Therefore, we need to handle those values appropriately. There are various ways to address this issue, but for now, we will simply remove the rows where players are suspended indefinitely. Let‚Äôs first identify the columns that contain the ‚ÄúIndef.‚Äù value mentioned in the error:"
      ],
      "metadata": {
        "id": "K6FviXLNiUFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nfl_suspension_df[nfl_suspension_df['games'] == \"Indef.\"]"
      ],
      "metadata": {
        "id": "B0PYVx-di3m5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that the issue is present in the first 6 rows, so we will filter out these problematic rows by keeping only the values that are not equal to ‚ÄúIndef.‚Äù using the **Not Equal Operator (!=)**. We will then assign this new filtered DataFrame back to the original variable to overwrite it."
      ],
      "metadata": {
        "id": "vPMg7KiVjA1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nfl_suspension_df = nfl_suspension_df[nfl_suspension_df['games'] != \"Indef.\"]\n",
        "nfl_suspension_df"
      ],
      "metadata": {
        "id": "uYgIshx4jUiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here‚Äôs how you can inspect 3 rows somewhere in the middle, for example, in the 150‚Äôs range, using .loc based on the index:"
      ],
      "metadata": {
        "id": "IShkzML4i_Xf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nfl_suspension_df.loc[150:153]"
      ],
      "metadata": {
        "id": "MCqADzS3k_Sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here‚Äôs how you can find a specific value in a DataFrame using .loc, by specifying both the index and the column name."
      ],
      "metadata": {
        "id": "5O9gwphwc9ud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nfl_suspension_df.loc[150, 'name']"
      ],
      "metadata": {
        "id": "0rEq59Ddlr78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now convert the `games` column into an integer datatype:"
      ],
      "metadata": {
        "id": "_TD2j3a9l8gM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nfl_suspension_df['games'] = nfl_suspension_df['games'].astype(int)\n",
        "nfl_suspension_df.dtypes"
      ],
      "metadata": {
        "id": "pImRXJEcmEEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPZB_yghJasu"
      },
      "source": [
        "### 2.2 Sorting Data\n",
        "Use **`.sort_values()`** to sort rows by one or more columns:\n",
        "\n",
        "```python\n",
        "df.sort_values(by='column_name') # Sort by a column in ascending order\n",
        "df.sort_values(by='column_name', ascending=False) # Sort a column in descending order\n",
        "df.sort_values(by=['column_name1', 'column_name2']) # Sort by two columns in ascending order\n",
        "\n",
        "```\n",
        "\n",
        "You can handle missing values while sorting by specifying `na_position='first'` or `na_position='last'`."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets sort our dataframe based on the column `year` in descending order to see the most recent year first, think about what looks different in the new sorted dataframe:"
      ],
      "metadata": {
        "id": "jACv7rO9QvYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nfl_suspension_df_sorted = nfl_suspension_df.sort_values(by=['year'] , ascending = False, )\n",
        "nfl_suspension_df_sorted"
      ],
      "metadata": {
        "id": "qNtPy4G7QvHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the rows are sorted by year, we see that the index for each row is all scrambled. Depending on the situation, if you don‚Äôt need to preserve the original row order, you may choose to reset the index to keep it sequential. This can be done as follows:\n",
        "\n",
        "```python\n",
        "df = df.reset_index(drop=True) # reset index and drop the old index information\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "wwV31rB1SBbH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "for our data will look something like this:"
      ],
      "metadata": {
        "id": "XW0pyIHbUirq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nfl_suspension_df_sorted = nfl_suspension_df_sorted.reset_index(drop=True)\n",
        "nfl_suspension_df_sorted"
      ],
      "metadata": {
        "id": "2hQ7IoXKUkyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShfhkcxeJasu"
      },
      "source": [
        "### 2.3 Grouping Data\n",
        "Pandas provides **`.groupby()`** for grouping rows by certain columns, then applying an **aggregation** (e.g., `sum()`, `mean()`, `count()`).\n",
        "\n",
        "```python\n",
        "df.groupby('column_name1')['column_name2'].sum() # Group by 1 column and aggregate by sum\n",
        "df.groupby(['column_name1', 'column_name2'])['column_name3'].mean() # Group by 2 columns and aggregate by the mean\n",
        "```\n",
        "\n",
        "This is very useful when you want to understand data aggregated at different levels. For example, what about if we want to know how many games suspended has been each year?\n",
        "\n",
        "We can answer this question by grouping by the `year` and applying a `sum()` of the `games`, lets apply this to our dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nfl_suspension_df_sorted.groupby('year')['games'].sum()"
      ],
      "metadata": {
        "id": "5iDrwrjNVZnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nfl_suspension_df_sorted.groupby(['year','category'])['games'].sum()"
      ],
      "metadata": {
        "id": "gX5a2WwZWk9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **`groupby()`** function in pandas is essential for analyzing and summarizing data based on different groups. It allows you to answer important questions, compare values across categories, and perform both numeric and non-numeric operations.\n",
        "\n",
        "**Is it only for numerical columns? **\n",
        "No! The `groupby()` function is not limited to **numeric columns**. While you can use aggregation functions like **`sum()`** and **`mean()`** for numerical data, you can also work with **non-numeric columns** to extract unique values, count occurrences, or apply custom functions.\n",
        "\n",
        "- **Numeric columns** ‚Üí Use aggregation functions like `sum()`, `mean()`, `max()`, etc.  \n",
        "- **Non-numeric columns** ‚Üí Use functions like `size()`, `unique()`, `apply()`, or custom functions."
      ],
      "metadata": {
        "id": "jzwBylAOU74G"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IshVk1boJasu"
      },
      "source": [
        "## 3. Using the .describe() Function\n",
        "**`.describe()`** in pandas provides summary statistics for numerical columns by default:\n",
        "\n",
        "- **count**: number of non-null values.\n",
        "- **mean**: average value.\n",
        "- **std**: standard deviation.\n",
        "- **min, max**: minimum and maximum values.\n",
        "- **25%, 50%, 75%**: quartiles.\n",
        "\n",
        "You can also pass arguments like `percentiles=[0.1, 0.9]` to see custom percentile values.\n",
        "\n",
        "Lets see the summary statistics for our nfl dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nfl_suspension_df_sorted.describe().round(2) # the last function .round() allows us to keep our values with as meny decimals we need"
      ],
      "metadata": {
        "id": "o2prGOzqb4gC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Do you remember what graph we could create from this summary statistics?**"
      ],
      "metadata": {
        "id": "Bs517nzfci2K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving a Dataframe in our google drive"
      ],
      "metadata": {
        "id": "qw_wcVzanzZk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To save a dataframe into google drive after cleaning, managing and wrangling the data if nessesary:\n",
        "\n",
        "1) Mount the google drive into google colab"
      ],
      "metadata": {
        "id": "zYxSFMCPoID5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "m_3aldwpn_ZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) use `df.to_csv(file_path, index=False)` to save the final version of the dataframe into the google drive. Change the name of the file in the path to any desired name.\n"
      ],
      "metadata": {
        "id": "_b7opKDoofVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define file path in Google Drive\n",
        "file_path = '/content/drive/MyDrive/Lehman College Spring 2025/MAT 301/datasets/nfl_final_version.csv'\n",
        "\n",
        "# Save DataFrame to CSV\n",
        "nfl_suspension_df_sorted.to_csv(file_path, index=False)\n",
        "\n",
        "print(\"File saved to Google Drive:\", file_path)"
      ],
      "metadata": {
        "id": "FoO3rv0Lo1jN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSeY7JInJasu"
      },
      "source": [
        "## 4.  Measures of Central Tendency\n",
        "\n",
        "**Packages Needed**  \n",
        "- **NumPy**: A fundamental Python package for scientific computing, providing efficient arrays and mathematical operations.   \n",
        "- **SciPy (`scipy.stats`)**: Builds on NumPy, offering advanced statistical tools. In particular, `trim_mean` helps us handle outliers by trimming data.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Mean\n",
        "- The **mean** (arithmetic average) of (n) numbers $(x_1, x_2, \\ldots, x_n)$ is:\n",
        "  $\n",
        "  \\text{Mean} = \\frac{x_1 + x_2 + \\dots + x_n}{n}\n",
        "  $\n",
        "- **Limitation**: The mean is sensitive to outliers.\n",
        "  \n",
        "**Example in Python (using Numpy):**\n",
        "```python\n",
        "df['column_name'].mean()\n",
        "```\n",
        "Lets calculate the overall mean games for our nfl dataframe:"
      ],
      "metadata": {
        "id": "ldUI_HJcZ5kF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "games_mean = nfl_suspension_df_sorted['games'].mean().round(2)\n",
        "\n",
        "print(f'the overall games mean is {games_mean}')"
      ],
      "metadata": {
        "id": "wGap4Z2YgydW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Median\n",
        "- The **median** is the middle value when the data is in order.\n",
        "  - If \\(n\\) (the number of data points) is **odd**, the median is the middle value.\n",
        "  - If \\(n\\) is **even**, the median is the average of the two middle values.\n",
        "- **Advantage**: The median is more robust to outliers.\n",
        "\n",
        "**Example in Python (using Pandas):**\n",
        "```python\n",
        "df['column_name'].median()\n",
        "```\n",
        "Lets calculate the overall median games for our nfl dataframe:"
      ],
      "metadata": {
        "id": "_bte55pGg1Fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "games_median = nfl_suspension_df_sorted['games'].median()\n",
        "\n",
        "print(f'the overall games median is {games_median}')"
      ],
      "metadata": {
        "id": "md0Xxcw-g2x3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 4.3 Mode\n",
        "- The **mode** is the most frequently occurring value in the data.\n",
        "- There can be more than one mode if multiple values tie for most frequent.\n",
        "- Especially useful for **categorical** or **discrete** data.\n",
        "\n",
        "**Example in Python (using Pandas):**\n",
        "```python\n",
        "df['column_name'].mode()\n",
        "```\n",
        "\n",
        "Lets calculate the overall mode games for our nfl dataframe:\n"
      ],
      "metadata": {
        "id": "GkgKVmvWg3C6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "games_mode = nfl_suspension_df_sorted['games'].mode()\n",
        "\n",
        "print(f'the overall games mode is: \\n ')\n",
        "\n",
        "display(games_mode)"
      ],
      "metadata": {
        "id": "mDIxRGDLg41r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4 Trimmed Mean\n",
        "- A **trimmed mean** removes a certain percentage of the smallest and largest values before computing the average, helping reduce the impact of outliers.\n",
        "\n",
        "A simple approach:\n",
        "1. Sort your values.\n",
        "2. Remove a fixed fraction (e.g., 10%) of the data from each end.\n",
        "3. Compute the mean of the remaining data.\n",
        "\n",
        "**Example in Python (using `scipy.stats`):**\n",
        "```python\n",
        "from scipy.stats import trim_mean\n",
        "\n",
        "trimmed = trim_mean(data_array, proportiontocut=0.1)  # Trim 10% from each tail\n",
        "```\n",
        "\n",
        "Lets calculate the 5% trimmed mean games for our nfl dataframe:"
      ],
      "metadata": {
        "id": "QgEhKcQ6g5GG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import trim_mean\n",
        "\n",
        "games_trim_mean = trim_mean(nfl_suspension_df_sorted['games'], proportiontocut=0.05).round(2)\n",
        "\n",
        "print(f'the overall games trim mean is {games_trim_mean}')"
      ],
      "metadata": {
        "id": "-tDc_pXggI21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets observe all the descriptive statistics together:"
      ],
      "metadata": {
        "id": "AITHK3s8kpdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Descriptive Statistics for games column in the nfl suspension dataframe\")\n",
        "\n",
        "print(f\"\\nMean : {games_mean}\\nMedian: {games_median}\\nMode: {games_mode[0]}\\nTrimmed Mean (5%): {games_trim_mean}\")"
      ],
      "metadata": {
        "id": "G8GJFHVsk2JU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discussion:\n",
        "\n",
        "Which metric should we use, and what are the pros and cons of each option?"
      ],
      "metadata": {
        "id": "OVAax4cRlzBk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQnjO0tpJasx"
      },
      "source": [
        "## 5. Summary and Key Takeaways\n",
        "- **Data Wrangling**: Slicing, sorting, and grouping are fundamental to shaping your dataset to answer specific questions.\n",
        "- **Central Tendency**: Mean, median, and mode each tell us different things about the \"center\" of data.\n",
        "- **Outliers**: Trimmed mean can help reduce the effect of extreme outliers.\n",
        "- **Choosing the Right Metric**: Always consider the data distribution and the presence of outliers when deciding which measure of central tendency to use.\n",
        "\n"
      ]
    }
  ]
}